# 任务

#### 近期核心开发任务（7-8月）

##### 任务九：数据中台加工优化（已完成DWD和DWS层，DWI层正在进行中）

​		数据中台之前是每天加工十天的数据，优化加工目标是每天只加工当天数据，根据时间字段严格增量。
​		设计首次执行，每日执行，指定开始结束时间执行逻辑，根据时间取出需要的数据
​		设计首次、每日、指定日期执行删除数据逻辑，防止多次插入数据导致重复数据出现（幂等逻辑）

##### 任务十：开发SQL存储过程脚本

  		1. 门店类别时段统计：根据早晚高峰、白天、夜间时间段，分别统计不同门店的不同商品类别销售情况，
       		粒度：月份、时间维度(工作日、周末、节假日)、时段(早高峰、晚高峰、日间、夜间、深夜)、门店代码、商品类别代码
        	2. 门店时段统计：	 根据早晚高峰、白天、夜间等时间段，分别统计不同门店的销售情况
            			粒度：月份、时间维度、时段、门店代码
        	3. 门店商品周期统计：最近7、14、30日聚合统计门店的不同商品销售情况
            			粒度：月份、统计周期(最近n天)、门店代码、商品代码

##### 任务十一：根据给定逻辑，增加表字段

分别为：ADS层门店类别月统计、门店商品月统计、门店年度统计、门店月度统计、门店类别货架月统计、

​			门店商品时统计、门店类别时统计、DIM层组织商品维度表，根据业务增加字段。

#### 大数据集群维护任务（5-6月）

##### 任务一：完成客户数据同步任务

（编辑同步任务脚本，主要涉及哪张表、同步方式（增量、全量）、增量依据时间（关联对应表获取时间字段）、
主键、频率）

##### 任务二：数据同步过程中，某些表脚本逻辑不严谨，导致出现重复数据。找出重复数据原因并修复重复数据，修改对应的脚本。

重复数据原因：1、抽取数据开始和结束时间不严谨，如果隔天对数据进行重复抽取，会导致数据重复
					修复脚本策略：增加幂等条件（delete from sink_table a using source_table b where a.id = b.id）
					修复重复数据策略：对目标表按某列或某几列进行去重（只需执行一次）
			  2、数据源不一致，同一数据来源于不同业务数据库，导致重复抽取。
					修复脚本策略：无需修复，注意同步数据从同一数据源同步
					修复重复数据策略：删除某一来源的数据，例如 （delete from table where data_source='Oracle'）
			  3、主键设置不合理，将不重复数据误认为重复数据
					修复脚本策略：将主键设置为不同数据唯一主键
					修复重复数据策略：无需修复，数据为不重复数据
					

##### 任务三：某用户门店组织id发生改变，增量表数据出现不唯一性，导致join,group by等操作与预期不一致

​		解决方案：将涉及到门店id不一致导致聚合、关联有误的脚本进行修复，关联维度表，获取最新的门店组织id
​		

##### 任务四：同步客户数据到大数据库

​		1、先进入远程仓库客户侧项目池，按照数据同步需求更改同步数据脚本。
​		2、登录跳板机远程连接客户计算机，登录Linux，再去相应路径使用Git命令拉取修改的配置文件
​		3、重启对应的docker服务
​		4、登录Web页面，启动需求表的抽数操作，根据抽取的速度以及数据的大小看是否需要对抽数配置进行修改
​		5、查看客户生产者日志，和集群消费者日志，判断数据抽取是否正确。如有需要，第二天第三天继续观察数据是否正确。
​		

##### 任务五：设计数据通道, Source为Greenplum, Sink为Flink. 编写代码实现Flink并发读取Greenplum数据

​			要求：Flink和Greenplum均设计分布式，Flink多并行度读取Greenplum每个segment节点数据，而不是直接读取master节点。
​			由于Flink和Greenplum官网都没有相应的连接器。所以需要自定义连接器，目前选择JDBC连接，实现了Flink多并行度读取
​			Greenplum数据，而读取Greenplum的segment节点数据，官网和其他平台资料较少，还没有实现此功能。 目前有五套实现方案。
​			方案一：通过JDBC直接读取master节点数据
​			方案二：开启Greenplum外部表支持，通过gpfdist工具将数据导出到外部表，并将外部表导出到其他文件系统，再用Flink进行读取
​			方案三：使用pg_export/pxf工具，将数据导出到Flink可以高效读取的其他文件系统或csv文件，再用Flink进行读取
​			方案四：使用中间件Kafka，将Greenplum数据导出到Kafka，再通过Flink进行读取 
​			方案五：自定义FlinkSource, 直接与segment通信，方案涉及到内部网络通信、内部数据结构等，实施难度较大。

		实现Flink读取Greenplum数据方案一，通过reduce和sum算子验证数据通道是否正确，并开启检查机制，实现精准一次性。（已完成）
		  方案2~4涉及到外部系统，暂不考虑。
		  方案五正在研发，计划将使用JDBC将Flink与所有segment节点建立连接，并通过异步I/O，并行读取每个segment节点数据。
	
		查找公司GP集群segment节点主机名称和端口号对应关系，尝试用JDBC将Flink和segment节点建立连接，尝试失败，Flink无法通过
	 		JDBC方式读取segment节点数据，这种读取数据方法暂时搁置。
		  Flink读取Greenplum数据发现两个问题，暂不处理。
			Question1: ExecutionEnvironment模式可以执行， 换成StreamExecutionEnvironment，设置为BATCH模式报错，不能执行。
			Question2: 开启env.getCheckpointConfig().setMinPauseBetweenCheckpoints(300000)设置后， 作业会像流一样处于挂起状态。

##### 任务六: 给定的脚本增加等待逻辑，使得后续任务在等到原始数据接收到之后再进行加工。

​		Question1：有部分脚本在等待超时后仍然没有等到数据，希望后续任务不受等待任务成功与否的影响，在等待任务下游增加参数，目的是
​		下游任务不受上游任务影响，不管成功与否，只要任务结束，下游任务就开始运行。
​		Question2：希望把失败的等待任务都罗列出来，自行解决失败任务。找到数据中台元数据连接信息，编写SQL罗列出airflow中失败的
​		task任务，以及所属的DAG任务、开始时间、结束时间、标签等信息。
​		

##### 任务七：邢台天天DAG任务某个脚本耗时较长，偶尔会超时退出，优化脚本

​		1、将可能造成耗时较长的语句后添加日志，重新运行是哪些语句导致脚本耗时较长。
​		2、耗时长的语句中包含了非等值连接和自连接。非等值连接没有采用hash算法，耗时较长。join大表时自连接使用了相同字段连接，造成了笛卡尔积
​		运算，想办法把自连接部分去掉。
​		3、将大表利用某个字段切分为三部分构造三张临时表，分别join三张临时表避免了笛卡尔积运算，脚本运行时间直接从1小时左右优化到2分钟。
​		

##### 任务八：数据异常，导致插入报错。

​		解决方法：在即将插入目标表前新建临时表，设置数据范围、过滤掉超长数据，再插入目标表。



### 长期任务

熟悉实时中台代码，根据自己的理解编写项目文档：
		1、自从系统学习大数据技术，编写的Java和Flink代码上万行，了解这个项目的过程中，突然感觉Java和Flink技术包罗万象，功能非常多，
通过此项目，最大的收益是让我对Java和Flink技术有了更多的了解，学习到了很多细节知识。
		2、通过编写文档，对markdown文档编写更加熟练，对于链图片等的处理更加得心应手
		2、流程图是了解项目很好的途径，通过这个任务，更加熟练地运用draw.io和Balsamiq Wireframes作图方法及细节。



# 技术经验总结

#### 数据重复（主键是维度字段，并非严格意义的主键）

重复数据原因：1、抽取数据开始和结束时间不严谨，如果隔天对数据进行重复抽取，会导致数据重复
					修复脚本策略：增加幂等条件（delete from sink_table a using source_table b where a.id = b.id）
					修复重复数据策略：对目标表按某列或某几列进行去重（只需执行一次）
			  2、数据源不一致，同一数据来源于不同业务数据库，导致重复抽取。
					修复脚本策略：无需修复，注意同步数据从同一数据源同步
					修复重复数据策略：删除某一来源的数据，例如 （delete from table where data_source='Oracle'）
			  3、主键设置不合理，将不重复数据误认为重复数据
					修复脚本策略：将主键设置为不同数据唯一主键
					修复重复数据策略：无需修复，数据为不重复数据

#### SQL开发：

​	表之间关联，根据粒度关联，避免产生笛卡尔积现象
​	cross join: 可以笛卡尔积式关联，常用来关联配置表。
​	多表full join时，可以将每张表的维度字段先建立临时表union起来，后续根据临时表left join其他事实表。
​	

#### SQL优化：

​	MPP数据库，设计好相应的分布键，尽量让数据平均地分布在每个节点。
​	某张表在join时只用到小部分字段，也可以提前新建临时表只存储后续需要的数据字段。
​	对于不可避免产生笛卡尔积的join操作，可以将这张表拆分为几张临时表，然后再分别join.
​	对于需要同一张表字段的join操作，可以考虑使用with公共表表达式。
​	group by字段比较多时，可以建立临时表存储相应字段，后续join，避免大量的排序操作。
​	

### 部分知识总结：

#### Flink输出 ctx.output和out.collect()区别：

​	ctx.output: 主要用于输出到 侧输出流， 性能损耗较高
​	out.collect(): 常规输出到下游、即主流， 性能损耗低

#### 保存点和检查点的区别：

checkpoint :设置时间，系统自行对运行状态进行存储，类似word自动保存

​	算法：Barrier对齐的精准一次（等所有节点barrier到来）

​			Barrier对齐的至少一次（不用等待互相等待）

​			非Barrier对齐的精准一次（不用等待，将数据和状态都进行存储）

savepoint：手动进行保存，类似于word手动保存

#### Flink状态：

#### Flink状态后端：

​	HashMapStateBackend：将状态数据以 Java 对象形式存储在堆内存中, 适合低延迟、数据量小场景
​	EmbeddedRocksDBStateBackend：使用RocksDB作为状态后端，可以将状态数据溢出存储到磁盘上，并持久化到远端文件系统中，
​	适合于大规模状态存储和生产环境。

#### Flink精准一次：

Source：Kafka设置offset

Sink：

幂等：HBase中rowkey,MySQL中主键等

事务：两阶段提交



#### Flink四种join区别：

​	Regular Join: 常规Join, Left Join和Right Join会产生回撤流
​	Interval Join: 时间关联Join，通过设置时间区间关联
​	Temporal Join: 动态表Join，通过时间字段关联，可以关联到全部数据而不是最新数据，例如关联快照表和拉链表。
​	Lookup Join: 维度表join，关联外部系统的维度表。

#### postgresql: 

​			json不会对相同key的value进行去重，jsonb会对相同key的value去重。jsonb功能更加丰富。
​			replace： 某个字段中部分字符替换为其他字符
​			string_to_array： 将字符串连接成数组。
​			unnest：根据某个分隔符，将数据炸裂。
​			DECIMAL和NUMERIC区别：DECIMAL和NUMERIC默认最大精度38位。如果插入的数值超出了指定的范围或精度，
​				DECIMAL会进行截断或四舍五入，而NUMERIC则可能会报错。

#### Scala闭包

将内部函数需要的所有变量打包保存在堆内存，不会因为外部函数调用结束释放栈内存中的变量而无法访问外部变量

#### Spark三大数据结构

RDD:弹性分布式数据集

累加器:分布式共享只写变量

广播变量:分布式共享只读变量

#### RDD、DataStream、DataSet区别和联系

###### 区别：

RDD 和 DataFrame ：DataFrame性能更好，因为底层做了执行优化，RDD没有字段和表信息，DataFrame类似二维表格

DataFrame 和 DataSet 的区别：DataSet相当于是对DataFrame的优化，row 类型，方便SQL操作

###### 联系：

RDD 和 DataFrame、DataSet之间可以相互转化 



#### Spark  ：yarn-client 和 yarn-cluster 两种模式

Driver 程序的运行节点yarn-client:Driver 程序运行在客户端，适用于交互、调试，希望立即看到 app 的输出

Driver 程序运行在由 ResourceManager 启动的 APPMaster，适用于生产环yarn-cluster



#### Hive On Spark 和 Spark On Hive

Hive On Spark: Hive SQL，计算引擎为rdd

Spark On Hive: Spark SQL, 计算引擎为DataFrame,DataSet



#### reduceByKey 与 groupByKey 的区别

reduceByKey：具有预聚合操作。 

groupByKey：没有预聚合。 在不影响业务逻辑的前提下，优先采用 reduceByKey

#### 宽依赖和窄依赖

窄依赖：一对一  或 多对一：eg:	map()`、`filter()

宽依赖：或一对多，eg:	`reduceByKey()`、`groupBy()`、`join()` 。宽依赖通常是性能瓶颈的所在，因为涉及到 shuffle 过程。

#### Hudi和Hive存储区别：

​	Hive在HDFS一张表一个目录，目录下有分区，分区有数据。元数据存放在数据库，默认derby，一般配置其他数据库，如Mysql
​	Hudi在HDFS表目录下除了数据，还有元数据目录，存放这张表元数据。

#### 排名函数区别

row_number(): 1,2,3

rank(): 1,1,3

dense_rank(): 1,1,2



### 远程仓库相关

远程仓库MarkDown文档插入图片
	1、在本地仓库创建文件夹，将图片放入文件夹，并上传到远程仓库
	2、在本地仓库相应.md文档插入远程仓库图片链接（快捷键Ctrl K），格式为： [图片名称](远程仓库图片链接)
	3、将本地仓库.md文档推送到远程仓库
	通过上面三个步骤，即可在本地仓库和远程仓库插入图片链接。

	也可以直接在.md文档显示图片，格式为 ![](远程git仓库图片相对路径) （例如远程仓库.md文档路径为http://github.hello.md, 图片路径为
	http://github.photo, 则可以表示为： ![](./photo) ）
	如果不是相对路径，而是图片链接，远程仓库会显示有图片标记的链接，点进去会看到图片，而本地文档只会有链接，而没有图片



