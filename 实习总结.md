# 任务

任务一：完成客户数据同步任务，（编辑同步任务脚本，主要涉及哪张表、同步方式（增量、全量）、增量依据时间（关联对应表获取时间字段）、
主键、频率）（只编辑同步脚本，上线任务由同事操作）

任务二：数据同步过程中，某些表脚本逻辑不严谨，导致出现重复数据。找出重复数据原因并修复重复数据，修改对应的脚本。
					

任务三：某用户门店组织id发生改变，增量表数据出现不唯一性，导致join,group by等操作与预期不一致
		解决方案：将涉及到门店id不一致导致聚合、关联有误的脚本进行修复，关联维度表，获取最新的门店组织id
		
任务四：同步客户数据到大数据库
		1、先进入远程仓库客户侧项目池，按照数据同步需求更改同步数据脚本。
		2、登录跳板机远程连接客户计算机，登录Linux，再去相应路径拉取修改的配置文件
		3、重启对应的docker服务
		4、登录Web页面，启动需求表的抽数操作，根据抽取的速度以及数据的大小看是否需要对抽数配置进行修改
		5、查看客户生产者日志，和集群消费者日志，判断数据抽取是否正确。如有需要，第二天第三天继续观察数据是否正确。

任务五：设计数据通道, Source为Greenplum, Sink为Flink. 编写代码实现Flink并发读取Greenplum数据
			要求：Flink和Greenplum均设计分布式，Flink多并行度读取Greenplum每个segment节点数据，而不是直接读取master节点。
			由于Flink和Greenplum官网都没有相应的连接器。所以需要自定义连接器，目前选择JDBC连接，今天实现了Flink多并行度读取
			Greenplum数据，而读取Greenplum的segment节点数据，官网和其他平台资料较少，还没有实现此功能。 目前有五套实现方案。
			方案一：通过JDBC直接读取master节点数据
			方案二：开启Greenplum外部表支持，通过gpfdist工具将数据导出到外部表，并将外部表导出到其他文件系统，再用Flink进行读取
			方案三：使用pg_export/pxf工具，将数据导出到Flink可以高效读取的其他文件系统或csv文件，再用Flink进行读取。
			方案四：使用中间件Kafka，将Greenplum数据导出到Kafka，再通过Flink进行读取 
			方案五：自定义FlinkSource, 直接与segment通信，方案涉及到内部网络通信、内部数据结构等，实施难度较大。
		实现Flink读取Greenplum数据方案一，通过reduce和sum算子验证数据通道是否正确，并开启检查机制，实现精准一次性。（已完成）
		  方案2~4涉及到外部系统，暂不考虑。
		  方案五正在研发，计划将使用JDBC将Flink与所有segment节点建立连接，并通过异步I/O，并行读取每个segment节点数据。


长期任务：熟悉实时中台代码，根据自己的理解编写项目文档：
		1、自从系统学习大数据技术，编写的Java和Flink代码上万行，了解这个项目的过程中，突然感觉Java和Flink技术包罗万象，功能非常多，
通过此项目，最大的收益是让我对Java和Flink技术有了更多的了解，学习到了很多细节知识。
		2、通过编写文档，对markdown文档编写更加熟练，对于链图片等的处理更加得心应手
		2、流程图是了解项目很好的途径，通过这个任务，更加熟练地运用draw.io和Balsamiq Wireframes作图方法及细节。



# 技术经验总结

### 数据重复

重复数据原因：1、抽取数据开始和结束时间不严谨，如果隔天对数据进行重复抽取，会导致数据重复
					修复脚本策略：增加幂等条件（delete from sink_table a using source_table b where a.id = b.id）
					修复重复数据策略：对目标表按某列或某几列进行去重（只需执行一次）
			  2、数据源不一致，同一数据来源于不同业务数据库，导致重复抽取。
					修复脚本策略：无需修复，注意同步数据从同一数据源同步
					修复重复数据策略：删除某一来源的数据，例如 （delete from table where data_source='Oracle'）
			  3、主键设置不合理，将不重复数据误认为重复数据
					修复脚本策略：将主键设置为不同数据唯一主键
					修复重复数据策略：无需修复，数据为不重复数据

### 远程仓库相关

远程仓库MarkDown文档插入图片
	1、在本地仓库创建文件夹，将图片放入文件夹，并上传到远程仓库
	2、在本地仓库相应.md文档插入远程仓库图片链接（快捷键Ctrl K），格式为： [图片名称](远程仓库图片链接)
	3、将本地仓库.md文档推送到远程仓库
	通过上面三个步骤，即可在本地仓库和远程仓库插入图片链接。

	也可以直接在.md文档显示图片，格式为 ![](远程git仓库图片相对路径) （例如远程仓库.md文档路径为http://github.hello.md, 图片路径为
	http://github.photo, 则可以表示为： ![](./photo) ）
	如果不是相对路径，而是图片链接，远程仓库会显示有图片标记的链接，点进去会看到图片，而本地文档只会有链接，而没有图片

### Flink相关	

Flink输出 ctx.output和out.collect()区别：
	ctx.output: 主要用于输出到 侧输出流， 性能损耗较高
	out.collect(): 常规输出到下游、即主流， 性能损耗低
	
Flink状态：

Flink状态后端：

# 心得	

接到新任务，感觉就是简单的修复，随着一步步的修改，发现需要注意的细节非常多，这个过程对脚本某些写法有了深入的理解。例如需要涉及到维度表的地方
需要修改，那么只会找维度表对应位置进行修改，修改过程发现某张临时表类似于 select * from 维度表A 这种情况，可能考虑这个临时表位置也需要修改。

有时候正确的思路固然没错，但是需要考虑正确思路所带来的时间和精力成本是否值当，有些时候将数据修复到绝对正确，细节是极其复杂的，如果当前方案
造成错误数据影响不是很大，而修复错误数据需要大量的时间和精力，也许就不用再对当前方案进行修复。需要用到某些正确数据，再对相应的数据脚本和
数据进行修复。

做的过程一步步有了更清晰的思路，把修改的地方记录下来，有新的修改思路的时候，记录下当前修复进度，等到将所有的脚本修改完，再将前面未修复完整的
数据整体重新修复一遍
需要改的SQL语法很简单，但是要考虑当前情况是否需要修改，相同的字段需要用哪个表的数据，需要细心思考。比如维度表某一字段更新，事实表需要关联
维度表，而事实表某一字段和维度表字段预期结果不一致，就需要用到关联另一个维度表获取最新的某个字段。而如果事实表需要关联的表A虽然不是维度表，
但是表A是依靠维度表创建的临时表，那么也有可能会出现数据不一致问题，这时候就需要考虑这个字段会不会影响最后的结果，答案如果是会，那么事实表
也要关联另一维度表来获取最新的数据字段。

重复的修复脚本工作，任务繁重，技术含量低，但是可以快速熟悉业务，为后续的开发做准备

